{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypten\n",
    "import crypten.optim\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch_nn_modules import ExampleNet, test\n",
    "from torch.utils.data import DataLoader\n",
    "import crypten.mpc as mpc\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/chz_sok_experiments/chz-sok-nn-experiments/nn_venv/lib/python3.8/site-packages/crypten/__init__.py:64: RuntimeWarning: CrypTen is already initialized.\n",
      "  warnings.warn(\"CrypTen is already initialized.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "crypten.init()\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_loss_fn = crypten.nn.CrossEntropyLoss()\n",
    "plain_loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base rand tensor([[ 101.1814,  -46.6721,  -87.3501,  -11.3377, -127.6126],\n",
      "        [ -83.2465, -133.9910, -169.2950,  -97.4745,  -75.6243],\n",
      "        [-105.4851,   14.7071,   93.2591,  -73.9188,  -17.2318]])\n",
      "target tensor([[0.0763, 0.2423, 0.2675, 0.2477, 0.1662],\n",
      "        [0.1838, 0.1963, 0.2546, 0.1342, 0.2310],\n",
      "        [0.1922, 0.1662, 0.3351, 0.1565, 0.1500]])\n"
     ]
    }
   ],
   "source": [
    "# loss tests\n",
    "\n",
    "# plain text\n",
    "plain_rand = torch.randn(3,5) * 100\n",
    "print(\"base rand\", plain_rand)\n",
    "plain_target = torch.randn(3, 5).softmax(dim=1)\n",
    "print(\"target\", plain_target)\n",
    "\n",
    "# crypten\n",
    "rand_enc = crypten.cryptensor(plain_rand)\n",
    "target_enc = crypten.cryptensor(plain_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax plain tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.8922e-04, 4.4818e-26, 2.0851e-41, 3.2388e-10, 9.9951e-01],\n",
      "        [0.0000e+00, 7.6784e-35, 1.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "softmax enc tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.1199e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9959e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# crypten softmax\n",
    "print(\"softmax plain\", plain_rand.softmax(dim=1))\n",
    "print(\"softmax enc\", rand_enc.softmax(dim=1).get_plain_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plaintext loss tensor(95.2656)\n",
      "crypten loss tensor(10.9005)\n"
     ]
    }
   ],
   "source": [
    "plain_loss = plain_loss_fn(plain_rand, plain_target)\n",
    "\n",
    "enc_loss = enc_loss_fn(rand_enc, target_enc)\n",
    "dec_loss = enc_loss.get_plain_text()\n",
    "\n",
    "print(\"plaintext loss\", plain_loss)\n",
    "crypten.print(\"crypten loss\", dec_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log, mul, neg: tensor([[2.9449e-03, 3.4815e+00, 3.8447e+00, 3.5598e+00, 2.3890e+00],\n",
      "        [1.4373e+00, 2.8215e+00, 3.6585e+00, 1.9289e+00, 8.9874e-03],\n",
      "        [2.7627e+00, 2.3881e+00, 1.2939e-02, 2.2491e+00, 2.1555e+00]])\n",
      "sum, div: tensor(10.9005)\n",
      "log_softmax tensor([[-4.1199e-04, -1.4785e+02, -1.8853e+02, -1.1252e+02, -2.2879e+02],\n",
      "        [-7.6233e+00, -5.8368e+01, -9.3672e+01, -2.1851e+01, -1.0986e-03],\n",
      "        [-1.9874e+02, -7.8552e+01, -4.1199e-04, -1.6718e+02, -1.1049e+02]])\n",
      "plain_softmax tensor([[ 0.0000e+00, -1.4785e+02, -1.8853e+02, -1.1252e+02, -2.2879e+02],\n",
      "        [-7.6227e+00, -5.8367e+01, -9.3671e+01, -2.1851e+01, -4.8935e-04],\n",
      "        [-1.9874e+02, -7.8552e+01,  0.0000e+00, -1.6718e+02, -1.1049e+02]])\n"
     ]
    }
   ],
   "source": [
    "rand_enc_softmax = rand_enc.softmax(dim=1)\n",
    "\n",
    "loss_values = rand_enc_softmax.log(input_in_01=True).mul_(target_enc).neg_()\n",
    "crypten.print(\"log, mul, neg:\", loss_values.get_plain_text())\n",
    "final_values = loss_values.sum().div_(target_enc.size(0))\n",
    "crypten.print(\"sum, div:\", final_values.get_plain_text())\n",
    "\n",
    "log_softmax = rand_enc.log_softmax(dim=1)\n",
    "print(\"log_softmax\", log_softmax.get_plain_text())\n",
    "plain_softmax = plain_rand.log_softmax(dim=1)\n",
    "print(\"plain_softmax\", plain_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_enc tensor([[ -0.0386, -14.3718, -14.3718, -14.3718, -14.3718],\n",
      "        [ -7.8191, -14.3718, -14.3718, -14.3718,  -0.0389],\n",
      "        [-14.3718, -14.3718,  -0.0386, -14.3718, -14.3718]])\n",
      "log_plain tensor([[ 0.0000e+00, -1.4785e+02, -1.8853e+02, -1.1252e+02, -2.2879e+02],\n",
      "        [-7.6227e+00, -5.8367e+01, -9.3671e+01, -2.1851e+01, -4.8935e-04],\n",
      "        [-1.9874e+02, -7.8552e+01,  0.0000e+00, -1.6718e+02, -1.1049e+02]])\n"
     ]
    }
   ],
   "source": [
    "log_enc = rand_enc_softmax.log(input_in_01=True)\n",
    "print(\"log_enc\", log_enc.get_plain_text())\n",
    "log_plain = plain_softmax\n",
    "print(\"log_plain\", log_plain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_mul_enc tensor([[-2.9449e-03, -3.4815e+00, -3.8447e+00, -3.5598e+00, -2.3890e+00],\n",
      "        [-1.4373e+00, -2.8215e+00, -3.6585e+00, -1.9289e+00, -8.9874e-03],\n",
      "        [-2.7627e+00, -2.3881e+00, -1.2939e-02, -2.2491e+00, -2.1555e+00]])\n",
      "log_mul_plain tensor([[ 0.0000e+00, -3.5819e+01, -5.0436e+01, -2.7871e+01, -3.8034e+01],\n",
      "        [-1.4013e+00, -1.1459e+01, -2.3846e+01, -2.9330e+00, -1.1306e-04],\n",
      "        [-3.8206e+01, -1.3054e+01,  0.0000e+00, -2.6165e+01, -1.6572e+01]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_mul_enc = log_enc.mul(target_enc)\n",
    "print(\"log_mul_enc\", log_mul_enc.get_plain_text())\n",
    "log_mul_plain = log_plain * plain_target\n",
    "print(\"log_mul_plain\", log_mul_plain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_mul_enc_neg tensor([[2.9449e-03, 3.4815e+00, 3.8447e+00, 3.5598e+00, 2.3890e+00],\n",
      "        [1.4373e+00, 2.8215e+00, 3.6585e+00, 1.9289e+00, 8.9874e-03],\n",
      "        [2.7627e+00, 2.3881e+00, 1.2939e-02, 2.2491e+00, 2.1555e+00]])\n",
      "log_mul_plain_neg tensor([[-0.0000e+00, 3.5819e+01, 5.0436e+01, 2.7871e+01, 3.8034e+01],\n",
      "        [1.4013e+00, 1.1459e+01, 2.3846e+01, 2.9330e+00, 1.1306e-04],\n",
      "        [3.8206e+01, 1.3054e+01, -0.0000e+00, 2.6165e+01, 1.6572e+01]])\n"
     ]
    }
   ],
   "source": [
    "log_mul_enc_neg = log_mul_enc.neg()\n",
    "print(\"log_mul_enc_neg\", log_mul_enc_neg.get_plain_text())\n",
    "log_mul_plain_neg = log_mul_plain.neg()\n",
    "print(\"log_mul_plain_neg\", log_mul_plain_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_mul_enc_neg_sum tensor(32.7015)\n",
      "log_mul_plain_neg_sum tensor(285.7968)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_mul_enc_neg_sum = log_mul_enc_neg.sum()\n",
    "print(\"log_mul_enc_neg_sum\", log_mul_enc_neg_sum.get_plain_text())\n",
    "log_mul_plain_neg_sum = log_mul_plain_neg.sum()\n",
    "print(\"log_mul_plain_neg_sum\", log_mul_plain_neg_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_enc tensor(10.9005)\n",
      "final_plain tensor(95.2656)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_enc = log_mul_enc_neg_sum.div(target_enc.size(0))\n",
    "print(\"final_enc\", final_enc.get_plain_text())\n",
    "final_plain = log_mul_plain_neg_sum / plain_target.size(0)\n",
    "print(\"final_plain\", final_plain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
